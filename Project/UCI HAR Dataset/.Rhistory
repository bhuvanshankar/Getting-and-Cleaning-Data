?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cram, -time)
select(cran, -time)
select(cran, -5:20)
select(cran, X:size)
-5:20
(5:20)
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(cran, r_version=<"3.0.2", country=="IN")
filter(cran, r_version<="3.0.2", country=="IN")
filter(cran, country == "US" | country =="IN")
filter(cran, size>100500, r_os=="linux-gnu")
filter(cran, r_version.is.na(c(3,5,NA,10)))
filter(cran, r_version=is.na(c(3,5,NA,10)))
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, r_verson.!is.na())
filter(cran, r_verson=!is.na())
filter(cran, !is.na(r_version))
cran2 <- select(cran, arrange())
cran2 <- select(cran, arrange(size:ip_id))
cran2 <- select(cran, arrange(c(size:ip_id))
f/
cran2 <- select(cran, arrange(size), arrange(ip_id))
cran2 <- select(cran, arrange(size, ip_id))
cran2 <- select(cran, arrange(size:ip_id))
cran2 <- select(cran, arrange())
cran2 <- select(cran, arrange(.size), arrange(.ip_id))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(ip_id, package, size)
cran3<-select(cran ip_id, package, size)
cran3<-select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb=size/2^20)
mutate(cran3, size_mb=size/2^20, size_gb=size_mb/2^10)
mutate(cran3, correct_size=size_gb+1000)
mutate(cran3, correct_size=size+1000)
summarize(cran, avg_bytes=mean(size))
swirl()
library(swirl)
Bhuvan
ls()
rm(list=ls())
quit()
unique(acs$AGEP)
source('~/.active-rstudio-document')
######## Question 1 ########
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "ClientID", "ClientSecret")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
stop_for_status(req)
content(req)
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
######## Question 2 ########
library(sqldf)
acs <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "acs.csv")
acs <- read.csv("acs.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
######## Question 3 ########
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
fUrl <- "http://biostat.jhsph.edu/~jleek/contact.html"
fUrl <- url(fUrl)
htmlCode <- readLines(fUrl)
close(fUrl)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", data.for)
data <- read.csv("data.for", header=T)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", data.for)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
data <- read.csv("data.for", header=T)
head(data)
View(data)
dim(data)
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
dim(data)
head(data)
?read.fwf
dframe <- read.fwf("data")
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
#data <- read.csv("data.for", header=T)
dframe <- read.fwf("data")
data <- read.csv("data.for", header=T)
View(data)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
#data <- read.csv("data.for", header=T)
dframe <- read.fwf("data", widths = " ")
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
data <- read.csv("data.for", header=T)
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
df <- read.fwf(file="data.for", widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
df
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
df <- read.fwf(file="data.for", header = TRUE, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
data <- read.csv("data.for", header=T)
df <- read.fwf(file="data.for", header = TRUE, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
data <- read.csv("data.for", header=T)
df <- read.fwf(file="data.for", widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
dim(df)
head(df)
head(data)
sum(df[, 4])
View(cran3)
install.packages("googlePublicData")
install.packages("googleVis")
library("googleVis", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:googleVis", unload=TRUE)
library("googleVis", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("Rserve")
source('~/Documents/git/CleaningGettingData/BaltimoreCamera.R')
View(CameraData)
source('~/Documents/git/CleaningGettingData/BaltimoreData/BaltimoreCamera.R')
View(CameraData)
source('~/Documents/git/CleaningGettingData/BaltimoreData/BaltimoreCamera.R')
View(CameraData)
autoplot(CameraData$Location.1)
library("ggplot2")
autoplot(CameraData$Location.1)
library("Deducer", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?deducer
deducer()
detach("package:Deducer", unload=TRUE)
library("maps", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
us.cities("Baltimore")
library("maps")
maps.us.cities
usa
data(usaMapEnv)
swirl()
library(swirl)
swirl()
mydf<-read.csv(path2csv, stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <-tbl_df(mydf)
rm("mydf")
cran
quit()
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- group_by(cran, package)
by_package
summarise(by_package, mean(size))
summarize(by_package, mean(size))
submit()
submit()
count = n(),
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
head(top_counts, 20)
library(swirl)
swirl()
arrange(top_counts, count)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
?chain
submit()
submit()
submit()
print(chain2)
print(cran)
submit()
submit()
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id,
country,
package,
size) %>%
mutate(size_mb <- size/2^20)
print
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id,
country,
package,
size) %>%
mutate(size_mb <- size/2^20)
print
submit()
submit()
size_mb <- mutate(size/2^20)
submit()
reset()
summarize(cran)
View(top_unique)
View(top_countries)
View(result3)
submit()
submit()
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb <- size/2^20)
submit()
submit()
submit()
submit()
submit()
library(swirl)
swirl()
?select
quit()
library(swirl)
rm(list=ls())
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, grade, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
students2
res
?separate
separate(res, sex_class, c("sex", "class"))
submit
submit()
submit()
submit()
students3
View(students3)
?gather
submit()
?spread()
?spread
submit()
View(students3)
submit()
submit()
reset()
submit()
submit()
submit()
submit()
reset()
reset()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
gather(class, grade, class1:class5, na.rm = TRUE)
gather(students3, class, grade, class1:class5, na.rm = TRUE)
# This script builds on the previous one by appending
# a call to spread(), which will allow us to turn the
# values of the test column, midterm and final, into
# column headers (i.e. variables).
#
# You only need to specify two arguments to spread().
# Can you figure out what they are? (Hint: You don't
# have to specify the data argument since we're using
# the %>% operator.
#
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, c("midterm","final")) %>%
print
submit()
submit()
submit()
submit()
submit()
?extract_numeric
extract_numeric("class5")
?mutate
submit()
submit()
students4
?select
submit()
submit()
?uniquw
?unique
submit()
submit()
library(swirl)
swirl()
passed
fail
failed
mutate(passed, "status", "passed")
passed <- passed %>% mutate(status="passed")
failed <- failed %>% mutate(status="passed")
failed <- failed %>% mutate(status="failed")
?rbind_list
rbind_list(passed,failed)
sat
?select
submit()
submit()
submit()
rm(ls)
rm()
?rm
rm(list=ls)
rm(list=ls())
clear
setwd("~/Documents/git/CleaningGettingData/Project")
source('~/Documents/git/CleaningGettingData/Project/script.R')
source('~/Documents/git/CleaningGettingData/Project/script.R')
source('~/Documents/git/CleaningGettingData/Project/script.R')
#setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
downloadDir <- "data"
zipFile <- filePath(downloadDir, "dataset.zip")
if(!file.exists(zipFile)) { download.file(url, zipFile, method = "curl") }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
dataDir <- downloadData()
#setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
file <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip")
zipFile <- filePath(file, "dataset.zip")
if(!file.exists(zipFile)) { download.file(url, zipFile, method = "curl") }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
dataDir <- downloadData()
"dataset.zip", method = "curl")
"dataset.zip")
?download.file
destfile = "dataset.zip")
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
?unzip
?if(!file.exists(zipFile)) { download.file(url, zipFile, method = "curl") }
downloadData <- function() {
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
?if(!file.exists(file)) { file }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
#setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
?if(!file.exists(file)) { file }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
dataDir <- downloadData()
#setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
?if(!file.exists(file)) { file }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(file, exdir = ".") }
dataDir
}
dataDir <- downloadData()
#setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
?if(!file.exists(file)) { file }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(dataset.zip, exdir = ".") }
dataDir
}
dataDir <- downloadData()
setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
unzipped <-unzip(file, "UCI HAR Dataset")
?unzip
unzipped <-unzip(file)
unzipped <-unzip("dataset.zip")
setwd("~/Documents/git/CleaningGettingData/Project")
### Download the dataset
download_data <- function() {
file <- download.file(url="http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "dataset.zip")
unzipped <-unzip("dataset.zip")
}
download_data
download_data()
setwd("~/Documents/git/CleaningGettingData/Project/UCI HAR Dataset")
setwd("~/Documents/git/CleaningGettingData/Project/UCI HAR Dataset")
# Importing Tables (Train)
x_train <- read.table("train/X_train.txt")
y_train <- read.table("train/y_train.txt")
subject_train <- read.table("train/subject_train.txt")
# Importing Tables (Test)
x_test <- read.table("test/X_test.txt")
y_test <- read.table("test/y_test.txt")
subject_test <- read.table("test/subject_test.txt")
View(x_test)
x_data <- rbind(x_train, x_test)
y_data <- rbind(y_train, y_test)
View(x_data)
subject <- rbind(subject_train, subject_test)
features <- read.table("features.txt")
View(features)
?grep
features <- read.table("features.txt")
m_stdev_features <- grep("-(mean|std)\\(\\)", features[,2])
x_data <- x_data[, m_stdev_features]
View(x_data)
# Subseting required columns and correcting the names
x_data <- x_data[, m_stdev_features]
names(x_data) <- features[m_stdev_features, 2]
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
View(y_data)
# Apply descriptive activity names
activity <- read.table("activity_labels.txt")
y_data[,1] <- activity[y_data[,1],2]
View(activity)
View(y_data)
names(y_data) <-"activity"
View(y_data)
names(y_data) <-"Activity"
View(subject)
names(subject) <- "Subject"
View(subject)
all_data <- cbind(x_data,y_data,subject)
View(all_data)
?ddply
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
source('~/.active-rstudio-document')
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
# Create tidy dataset
tidy_data <- ddply(all_data, .(subject, activity), function(x), colMeans(x[,1:66]))
write.table(tidy_data, "averages_data.txt", row.names=FALSE)
tidydata <- all_data %>%
ddply(c(subject,activity, function(x), colMeans(x[,1:66]))) %>%
write.table("averages_data.txt", row.names=FALSE)
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
tidydata <- all_data %>% ddply(c(subject,activity, function(x), colMeans(x[,1:66]))) %>% write.table("averages_data.txt", row.names=FALSE)
# Create tidy dataset
averages_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.names=FALSE)
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
# Create tidy dataset
averages_data <- ddply(all_data, .(Subject, Activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.names=FALSE)
View(all_data)
View(averages_data)
source('~/Documents/git/CleaningGettingData/Project/run_analysis.R')
View(averages_data)
library(ggplot2)
?ggplot2
?ggplot
ggplot(averages_data)
ggplot(averages_data, Activity)
